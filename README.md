# ğŸ™ï¸ Emotion Recognition from Speech

This is a Flask-based web application that predicts human emotion from speech audio files. The system uses pre-trained machine learning models to classify emotions such as **Happy**, **Sad**, **Angry**, **Neutral**, and others, based on audio feature extraction (like MFCCs).

 ## ğŸ“ Project Structure
emotion-recognition/
â”‚
â”œâ”€â”€ audio/ # Stores recorded/test audio files
â”‚
â”œâ”€â”€ model/ # Pre-trained model and encoders
â”‚ â”œâ”€â”€ label_encoder.pkl # Encoder mapping emotion labels
â”‚ â””â”€â”€ label2_encoder.pkl # (Optional secondary encoder)
â”‚
â”œâ”€â”€ templates/ # HTML templates (for Flask)
â”‚ â”œâ”€â”€ index.html # Main UI page
â”‚ â””â”€â”€ ab.c # [Can be removed if not used]
â”‚
â”œâ”€â”€ uploaded_files/ # Stores uploaded .wav files temporarily
â”‚
â”œâ”€â”€ app.py # Flask application entry point
â”œâ”€â”€ README.md # Project documentation


## ğŸš€ Features

- ğŸ§ Upload `.wav` audio files via web UI
- ğŸ“Š Extracts MFCC features from audio
- ğŸ¤– Predicts emotion using a trained model
- ğŸ’¬ Displays predicted emotion on screen

---

## ğŸ› ï¸ Tech Stack

- **Frontend**: HTML (Jinja2 templating)
- **Backend**: Python, Flask
- **Audio Processing**: Librosa, SoundFile
- **Modeling**: Scikit-learn / Keras
- **Others**: NumPy, Pandas, Pickle
  ---
 ğŸ§  Model Details
The trained model uses MFCC features extracted from .wav files.

Encoders (label_encoder.pkl and label2_encoder.pkl) are used to transform labels during prediction.

You can update the model or add deep learning support in future iterations.
 ğŸ”® Future Improvements
ğŸ™ï¸ Real-time microphone-based prediction

ğŸŒ Support for multilingual datasets

ğŸ§  Upgrade to CNN/LSTM or transformer-based models

ğŸ“ˆ Visual feedback (waveform, spectrograms)
